{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PKT_002_tf_initial.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMdRHx1tR0B4UXfMSIefPHM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/son50git/PKT_002_Convolutional/blob/master/PKT_002_tf_initial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpCBv0VmqeMI",
        "outputId": "f7dac87b-2f96-4a35-bf0e-5b327b9e6f05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "# Creating TensorFlow object \n",
        "hello_constant = tf.constant('Hello World!', name = 'hello_constant')\n",
        "# Creating a session object for execution of the computational graph\n",
        "with tf.Session() as sess:\n",
        "\n",
        "    # Implementing the tf.constant operation in the session\n",
        "    output = sess.run(hello_constant)\n",
        "    print(output)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Hello World!'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkjBGoBYrt2x",
        "outputId": "ca1b573f-7134-45a3-8eea-68387f499914",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "# A is an int32 tensor with rank = 0\n",
        "A = tf.constant(123) \n",
        "# B is an int32 tensor with dimension of 1 ( rank = 1 ) \n",
        "B = tf.constant([123,456,789]) \n",
        "# C is an int32 2- dimensional tensor \n",
        "C = tf.constant([ [123,456,789], [222,333,444] ])\n",
        "\n",
        "#Creating a session object for execution of the computational graph\n",
        "with tf.Session() as sess:\n",
        "    #Implementing the tf.constant operation in the session\n",
        "    # output = sess.run(A) # 123\n",
        "    # output = sess.run(B) # [123 456 789]\n",
        "    output = sess.run(C) # [[123 456 789] [222 333 444]]\n",
        "    print(output)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[123 456 789]\n",
            " [222 333 444]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QQTLhAQsvJs",
        "outputId": "54a15d14-4de2-498f-ce54-d01f87150844",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "constant_x = tf.constant(5, name='constant_x')\n",
        "variable_y = tf.Variable(constant_x + 5, name='variable_y')\n",
        "print (variable_y) # <tf.Variable 'variable_y_1:0' shape=() dtype=int32_ref>\n",
        "\n",
        "#initialize all variables\n",
        "init = tf.global_variables_initializer()\n",
        "# All variables are now initialized\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    print(sess.run(variable_y)) # 10"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'variable_y_4:0' shape=() dtype=int32_ref>\n",
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNYim0QQtqDK",
        "outputId": "604aa3cc-f034-4497-9208-5b0cc805bc7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "x = tf.placeholder(tf.string)\n",
        "y = tf.placeholder(tf.int32, None)\n",
        "z = tf.placeholder(tf.float32, None)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    output = sess.run(x, feed_dict={x: 'Welcome to CNN', y: 123, z: 123.45})\n",
        "    print(output) # Welcome to CNN\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    output = sess.run(y, feed_dict={x: 'Welcome to CNN', y: 123, z: 123.45})\n",
        "    print(output) # 123"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Welcome to CNN\n",
            "123\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AA1JJbQjuqzA",
        "outputId": "a4aac172-ba96-4feb-a9d3-79759a1b5bba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "x3 = tf.placeholder(\"float\", [None, 3]) # NONE means 'as long as you have three elements in the row'\n",
        "x2 = tf.placeholder(\"float\", [None, 2])\n",
        "z3 = 2 * x3\n",
        "z2 = 2 * x2\n",
        "\n",
        "with tf.Session() as session:\n",
        "    input_data = [[1, 2, 3],\n",
        "                 [4, 5, 6],]\n",
        "    result = session.run(z3, feed_dict={x3: input_data})\n",
        "    print(result)  # [[ 2.  4.  6.][ 8. 10. 12.]]\n",
        "\n",
        "with tf.Session() as session:\n",
        "    input_data = [[1, 2],\n",
        "                 [4, 5],]\n",
        "    result = session.run(z2, feed_dict={x2: input_data}) # [[ 2.  4.] [ 8. 10.]]\n",
        "    print(result)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 2.  4.  6.]\n",
            " [ 8. 10. 12.]]\n",
            "[[ 2.  4.]\n",
            " [ 8. 10.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HR_OeHDGJDm1",
        "outputId": "0b97a3b2-1242-454f-a1e2-7c3d21993ffb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "softmax_data = [0.1,0.5,0.4]\n",
        "onehot_data =  [0.0,1.0,0.0]\n",
        "\n",
        "softmax = tf.placeholder(tf.float32)\n",
        "onehot_encoding = tf.placeholder(tf.float32)\n",
        "tmp = tf.log(softmax) # NO values # only for verification: [-2.3025851 -0.6931472 -0.9162907]\n",
        "tmp = tf.multiply(onehot_encoding,tf.log(softmax)) # NO values # only for verification: [-0. -0.6931472 -0.]\n",
        "tmp = - tf.reduce_sum(tf.multiply(onehot_encoding,tf.log(softmax))) # NO values # only for verification: 0.6931472  \n",
        "with tf.Session() as session:\n",
        "    print(session.run(tmp, feed_dict={softmax:softmax_data, onehot_encoding:onehot_data} ))\n",
        "\n",
        "tmp2 = tf.nn.softmax_cross_entropy_with_logits(logits=tf.log(softmax), labels=onehot_encoding)\n",
        "with tf.Session() as session:\n",
        "    print(session.run(tmp2, feed_dict={softmax:softmax_data, onehot_encoding:onehot_data} ))\n",
        "\n",
        "# summary\n",
        "# the following two are equivalent\n",
        "# tf.nn.softmax_cross_entropy_with_logits(logits=A, labels=B)\n",
        "# - tf.reduce_sum(tf.multiply(B, A)))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931472\n",
            "0.6931472\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJwrilKIwfTm",
        "outputId": "fae44d59-b3e6-4dbb-82e7-e2ff9a79fa79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "softmax_data = [0.1,0.5,0.4]\n",
        "onehot_data = [0.0,1.0,0.0]\n",
        "\n",
        "softmax = tf.placeholder(tf.float32)\n",
        "onehot_encoding = tf.placeholder(tf.float32)\n",
        "\n",
        "cross_entropy = - tf.reduce_sum(tf.multiply(onehot_encoding,tf.log(softmax)))\n",
        "\n",
        "cross_entropy_loss = tf.nn.softmax_cross_entropy_with_logits(logits=tf.log(softmax), labels=onehot_encoding)\n",
        "\n",
        "with tf.Session() as session:\n",
        "    print(session.run(cross_entropy,feed_dict={softmax:softmax_data, onehot_encoding:onehot_data} ))\n",
        "    print(session.run(cross_entropy_loss,feed_dict={softmax:softmax_data, onehot_encoding:onehot_data} ))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931472\n",
            "0.6931472\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T50oMvvLbCrO",
        "outputId": "39b10ad6-15c3-4e8a-db0e-d0e4a5c3a3a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# softmax = tf.exp(logits) / tf.reduce_sum(tf.exp(logits), axis)\n",
        "# Computes softmax activations\n",
        "# softmax = tf.nn.softmax(logits)\n",
        "\n",
        "# import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "logit_data = [2.0, 1.0, 0.1]\n",
        "logits = tf.placeholder(tf.float32)\n",
        "\n",
        "tmp = tf.exp(logits)  # verification: [7.389056  2.7182817 1.105171 ]\n",
        "tmp = tf.reduce_sum(tf.exp(logits))  # verification: 11.212509\n",
        "tmp = tf.exp(logits) / tmp\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    output = sess.run(tmp, feed_dict={logits: logit_data})\n",
        "    print( output )  # [0.6590011  0.24243295 0.09856589]\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.6590011  0.24243295 0.09856589]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IT1fF0KGZ2jk",
        "outputId": "63187c4c-6577-4d33-b641-9ee95efc9298",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "logit_data = [2.0, 1.0, 0.1]\n",
        "logits = tf.placeholder(tf.float32)\n",
        "softmax = tf.nn.softmax(logits)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    output = sess.run(softmax, feed_dict={logits: logit_data})\n",
        "    print( output )\n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.6590012  0.24243298 0.09856589]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}